# Churn-analysis-sql-project


ğŸ” Customer Churn Analysis & Prediction Project

Project Overview

Understanding why customers leave is as critical as acquiring them. In this project, I performed a Churn Analysis using Python to uncover customer behavior patterns, build predictive models, and generate actionable insights that businesses can use to reduce churn and improve retention.

I approached this analysis from both descriptive and predictive anglesâ€”telling the story behind churn using data, and then building models to anticipate and mitigate it.

ğŸ› ï¸ Tools and Technologies Used

â€¢	Python (Jupyter Notebook) â€“ Analysis and modeling

â€¢	Pandas, NumPy â€“ Data handling and feature engineering

â€¢	Matplotlib, Seaborn â€“ Visualizations and trend analysis

â€¢	Scikit-learn â€“ Classification models, performance metrics

â€¢	SQLite (via Pandas) â€“ Simulated database-style querying for churn metrics

â“ Key Business Questions Addressed

1.	What are the common traits of customers who churn vs. those who stay?

2.	Which features (e.g., Age, Credit Score, Balance) are strong churn predictors?

3.	Can we build a model that accurately predicts whether a customer will churn?

4.	How can the business segment and retain high-risk customers early?

ğŸ”„ Methodology

1.	Data Cleaning

â€¢	Handled missing/null values and validated datatypes.

â€¢	Removed duplicates and standardized column formats.

â€¢	Checked for data leakage and label imbalance.

2.	Exploratory Data Analysis (EDA)

â€¢	Explored distributions of key features (e.g., Age, Credit Score, Balance).

â€¢	Created visual segments of customers (e.g., by Tenure, NumOfProducts, IsActive).

â€¢	Analyzed correlations and outliers to find behavioral patterns.


3.	Feature Engineering

â€¢	Created new features such as:

o	EngagementScore: Composite metric of activity level and tenure

o	HighValueCustomer: Based on balance, salary, and product usage

â€¢	One-hot encoded categorical variables

4.	Model Building

â€¢	Built and evaluated multiple models:

o	Logistic Regression

o	Random Forest

o	XGBoost

â€¢	Used cross-validation, confusion matrix, ROC-AUC, and F1 Score to evaluate performance

5.	Segmentation & Insights

â€¢	Clustered users by churn risk and value tier

â€¢	Generated insight-rich tables and graphs to support decision-making



ğŸ“Š Key Findings

â€¢	ğŸ’° High balance but low product usage was a strong churn indicator.

â€¢	ğŸ”¢ Credit score < 600 and tenure < 3 years increased churn probability.

â€¢	ğŸ§Š Inactive customers were 3.5x more likely to churn than active ones.

â€¢	ğŸš© Churn was more common among customers with only one product or non-engaged behavior.

â€¢	ğŸ§  Random Forest outperformed other models with ~86% ROC-AUC and strong recall on the churn class.

ğŸ“Œ Business Impact

â€¢	Helps target at-risk customers with personalized retention campaigns

â€¢	Enables proactive interventions like loyalty offers or service upgrades

â€¢	Supports product, marketing, and customer success teams in improving Customer Lifetime Value (CLV)

ğŸ§  What This Project Demonstrates

â€¢	My ability to extract insights from raw data and tell a compelling churn narrative

â€¢	Solid grasp of EDA, feature selection, and classification modeling

â€¢	Business-focused thinking with actionable outcomes

â€¢	Experience translating models into stakeholder-friendly visuals and insights

â€¢	Hands-on use of Pythonâ€™s data stack for real-world classification tasks


